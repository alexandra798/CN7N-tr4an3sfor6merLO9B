{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12444888,"sourceType":"datasetVersion","datasetId":7850277}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# limit gpu memory\nimport tensorflow as tf\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n    # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n        print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:27:04.590801Z","iopub.execute_input":"2025-07-14T05:27:04.591079Z","iopub.status.idle":"2025-07-14T05:27:21.174345Z","shell.execute_reply.started":"2025-07-14T05:27:04.591054Z","shell.execute_reply":"2025-07-14T05:27:21.173553Z"}},"outputs":[{"name":"stderr","text":"2025-07-14 05:27:06.458874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752470826.705936      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752470826.777408      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"1 Physical GPUs, 1 Logical GPUs\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752470841.169262      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import (Input, Conv2D, Dense, Dropout, \n                                     Reshape, MaxPooling2D, Flatten, \n                                     LayerNormalization, MultiHeadAttention,\n                                     GlobalAveragePooling1D)\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tensorflow.keras import utils as np_utils\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nnp.random.seed(1)\ntf.random.set_seed(2)\n\n# Input data files are available in the read-only \"../input/\" directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:27:31.366996Z","iopub.execute_input":"2025-07-14T05:27:31.367484Z","iopub.status.idle":"2025-07-14T05:27:31.584977Z","shell.execute_reply.started":"2025-07-14T05:27:31.367459Z","shell.execute_reply":"2025-07-14T05:27:31.584333Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/fi-2010/Train_Dst_NoAuction_DecPre_CF_7.txt\n/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_9.txt\n/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_8.txt\n/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_7.txt\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"Data preparation","metadata":{}},{"cell_type":"code","source":"def prepare_x(data):\n    df1 = data[:40, :].T\n    return np.array(df1)\n\ndef get_label(data):\n    lob = data[-5:, :].T\n    return lob\n\ndef data_classification(X, Y, T):\n    [N, D] = X.shape\n    df = np.array(X)\n    dY = np.array(Y)\n    dataY = dY[T - 1:N]\n    dataX = np.zeros((N - T + 1, T, D))\n    for i in range(T, N + 1):\n        dataX[i - T] = df[i - T:i, :]\n    return dataX.reshape(dataX.shape + (1,)), dataY\n\ndef prepare_x_y(data, k, T):\n    x = prepare_x(data)\n    y = get_label(data)\n    x, y = data_classification(x, y, T=T)\n    y = y[:,k] - 1\n    y = np_utils.to_categorical(y, 3)\n    return x, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:29:39.962901Z","iopub.execute_input":"2025-07-14T05:29:39.963187Z","iopub.status.idle":"2025-07-14T05:29:39.969393Z","shell.execute_reply.started":"2025-07-14T05:29:39.963164Z","shell.execute_reply":"2025-07-14T05:29:39.968581Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dec_data = np.loadtxt('/kaggle/input/fi-2010/Train_Dst_NoAuction_DecPre_CF_7.txt')\ndec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\ndec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\ndec_test1 = np.loadtxt('/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_7.txt')\ndec_test2 = np.loadtxt('/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_8.txt')\ndec_test3 = np.loadtxt('/kaggle/input/fi-2010/Test_Dst_NoAuction_DecPre_CF_9.txt')\ndec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n\nk = 4  # 预测时间范围\nT = 100  # 单个输入的长度\nn_hiddens = 64\ncheckpoint_filepath = 'my_model_weights.weights.h5'\n\ntrainX_CNN, trainY_CNN = prepare_x_y(dec_train, k, T)\nvalX_CNN, valY_CNN = prepare_x_y(dec_val, k, T)\ntestX_CNN, testY_CNN = prepare_x_y(dec_test, k, T)\n\nprint(trainX_CNN.shape, trainY_CNN.shape)\nprint(valX_CNN.shape, valY_CNN.shape)\nprint(testX_CNN.shape, testY_CNN.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:27:37.369208Z","iopub.execute_input":"2025-07-14T05:27:37.369772Z","iopub.status.idle":"2025-07-14T05:28:06.086382Z","shell.execute_reply.started":"2025-07-14T05:27:37.369747Z","shell.execute_reply":"2025-07-14T05:28:06.085672Z"}},"outputs":[{"name":"stdout","text":"(203701, 100, 40, 1) (203701, 3)\n(50851, 100, 40, 1) (50851, 3)\n(139488, 100, 40, 1) (139488, 3)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"Model Architecture","metadata":{}},{"cell_type":"code","source":"class TransformerEncoderBlock(layers.Layer):\n    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1):\n        super(TransformerEncoderBlock, self).__init__()\n        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n        self.ffn = keras.Sequential([\n            Dense(ff_dim, activation=None),\n            layers.LeakyReLU(negative_slope=0.01),\n            Dense(d_model),\n        ])\n        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n        self.dropout1 = Dropout(dropout_rate)\n        self.dropout2 = Dropout(dropout_rate)\n\n    def call(self, inputs, training=None):\n        # 多头注意力\n        attn_output = self.att(inputs, inputs)\n        attn_output = self.dropout1(attn_output, training=training)\n        out1 = self.layernorm1(inputs + attn_output)\n        \n        # 前馈网络\n        ffn_output = self.ffn(out1)\n        ffn_output = self.dropout2(ffn_output, training=training)\n        return self.layernorm2(out1 + ffn_output)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:29:50.961007Z","iopub.execute_input":"2025-07-14T05:29:50.961325Z","iopub.status.idle":"2025-07-14T05:29:50.967892Z","shell.execute_reply.started":"2025-07-14T05:29:50.961274Z","shell.execute_reply":"2025-07-14T05:29:50.967036Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# 模型架构\n\ndef create_deeplob_transformer(T, NF, n_transformer_blocks=2, d_model=64, num_heads=4, ff_dim=96):\n    input_lmd = Input(shape=(T, NF, 1))\n    \n    # 卷积块1\n    \n    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n    conv_first1 = layers.LeakyReLU(negative_slope=0.01)(conv_first1)\n    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n    conv_first1 = layers.LeakyReLU(negative_slope=0.01)(conv_first1)\n    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n    conv_first1 = layers.LeakyReLU(negative_slope=0.01)(conv_first1)\n    \n    # 卷积块2\n\n    conv_first2 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n    conv_first2 = layers.LeakyReLU(negative_slope=0.01)(conv_first2)\n    conv_first2 = Conv2D(32, (4, 1), padding='same')(conv_first2)\n    conv_first2 = layers.LeakyReLU(negative_slope=0.01)(conv_first2)\n    conv_first2 = Conv2D(32, (4, 1), padding='same')(conv_first2)\n    conv_first2 = layers.LeakyReLU(negative_slope=0.01)(conv_first2)\n\n    # reshape数据以适应Transformer输入\n    \n    target_shape = (int(conv_first2.shape[1]), int(conv_first2.shape[2]) * int(conv_first2.shape[3]))\n    conv_reshape = Reshape(target_shape)(conv_first2)\n\n    \n    # 位置编码\n    positions = tf.range(start=0, limit=conv_reshape.shape[1], delta=1)\n    position_embedding = layers.Embedding(input_dim=conv_reshape.shape[1], output_dim=d_model)(positions)\n    \n    # 投影到d_model维度\n    transformer_input = Dense(d_model)(conv_reshape)\n    transformer_input = transformer_input + position_embedding\n    \n    # 应用多个transformer encoder块\n    x = transformer_input\n    for _ in range(n_transformer_blocks):\n        x = TransformerEncoderBlock(d_model, num_heads, ff_dim, dropout_rate=0.2)(x)\n    \n    # 全局平均池化\n    x = GlobalAveragePooling1D()(x)\n    \n\n    x = Dropout(0.4)(x)\n    out = Dense(3, activation='softmax')(x)\n    \n    model = Model(inputs=input_lmd, outputs=out)\n    \n    # 使用带有weight_decay的Adam优化器\n    adam = keras.optimizers.Adam(learning_rate=0.0003, weight_decay=3e-4)\n    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:29:53.812654Z","iopub.execute_input":"2025-07-14T05:29:53.813157Z","iopub.status.idle":"2025-07-14T05:29:53.822091Z","shell.execute_reply.started":"2025-07-14T05:29:53.813131Z","shell.execute_reply":"2025-07-14T05:29:53.821200Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"deeplob = create_deeplob_transformer(trainX_CNN.shape[1], trainX_CNN.shape[2])\n\ndeeplob.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:29:58.393568Z","iopub.execute_input":"2025-07-14T05:29:58.394059Z","iopub.status.idle":"2025-07-14T05:30:00.928055Z","shell.execute_reply.started":"2025-07-14T05:29:58.394034Z","shell.execute_reply":"2025-07-14T05:30:00.927480Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │            \u001b[38;5;34m96\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m4,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m4,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m2,080\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m4,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m4,128\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m320\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m20,544\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ add (\u001b[38;5;33mAdd\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_encoder_block       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m79,072\u001b[0m │\n│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_encoder_block_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m79,072\u001b[0m │\n│ (\u001b[38;5;33mTransformerEncoderBlock\u001b[0m)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m195\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,544</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_encoder_block       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,072</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ transformer_encoder_block_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,072</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoderBlock</span>)       │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m197,571\u001b[0m (771.76 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,571</span> (771.76 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m197,571\u001b[0m (771.76 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">197,571</span> (771.76 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"Model Training","metadata":{}},{"cell_type":"code","source":"\n# 模型检查点回调\nmodel_checkpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True,\n    verbose=1\n)\n\n# 早停回调\nearly_stopping_callback = EarlyStopping(\n    monitor='val_loss',\n    patience=5,  # 如果验证损失在5个epoch内没有改善，则停止训练\n    restore_best_weights=True,  # 恢复最佳权重\n    verbose=1\n)\n\n# 降低学习率\nreduce_learningrate_callback = ReduceLROnPlateau(\n    monitor='val_loss',  \n    factor=0.2,          \n    patience=2,\n    min_lr=1e-6\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:30:04.378327Z","iopub.execute_input":"2025-07-14T05:30:04.378904Z","iopub.status.idle":"2025-07-14T05:30:04.383582Z","shell.execute_reply.started":"2025-07-14T05:30:04.378882Z","shell.execute_reply":"2025-07-14T05:30:04.382620Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 训练模型\nhistory = deeplob.fit(\n    trainX_CNN, trainY_CNN, \n    validation_data=(valX_CNN, valY_CNN), \n    epochs=50,\n    batch_size=128, \n    verbose=2, \n    callbacks=[model_checkpoint_callback, early_stopping_callback, reduce_learningrate_callback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:30:13.344382Z","iopub.execute_input":"2025-07-14T05:30:13.344830Z","iopub.status.idle":"2025-07-14T05:54:02.232641Z","shell.execute_reply.started":"2025-07-14T05:30:13.344809Z","shell.execute_reply":"2025-07-14T05:54:02.231898Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752471033.585963      94 service.cc:148] XLA service 0x79ed4c004630 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752471033.586707      94 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1752471034.648971      94 cuda_dnn.cc:529] Loaded cuDNN version 90300\nI0000 00:00:1752471041.725542      94 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.08936, saving model to my_model_weights.weights.h5\n1592/1592 - 65s - 41ms/step - accuracy: 0.4155 - loss: 1.0337 - val_accuracy: 0.3723 - val_loss: 1.0894 - learning_rate: 3.0000e-04\nEpoch 2/50\n\nEpoch 2: val_loss did not improve from 1.08936\n1592/1592 - 34s - 22ms/step - accuracy: 0.4253 - loss: 1.0152 - val_accuracy: 0.3723 - val_loss: 1.0895 - learning_rate: 3.0000e-04\nEpoch 3/50\n\nEpoch 3: val_loss did not improve from 1.08936\n1592/1592 - 35s - 22ms/step - accuracy: 0.5742 - loss: 0.8442 - val_accuracy: 0.3723 - val_loss: 1.0954 - learning_rate: 3.0000e-04\nEpoch 4/50\n\nEpoch 4: val_loss improved from 1.08936 to 1.07659, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.6467 - loss: 0.7418 - val_accuracy: 0.3781 - val_loss: 1.0766 - learning_rate: 6.0000e-05\nEpoch 5/50\n\nEpoch 5: val_loss improved from 1.07659 to 0.93086, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.6837 - loss: 0.6975 - val_accuracy: 0.5076 - val_loss: 0.9309 - learning_rate: 6.0000e-05\nEpoch 6/50\n\nEpoch 6: val_loss improved from 0.93086 to 0.90831, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7059 - loss: 0.6652 - val_accuracy: 0.5232 - val_loss: 0.9083 - learning_rate: 6.0000e-05\nEpoch 7/50\n\nEpoch 7: val_loss improved from 0.90831 to 0.88859, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7179 - loss: 0.6483 - val_accuracy: 0.5460 - val_loss: 0.8886 - learning_rate: 6.0000e-05\nEpoch 8/50\n\nEpoch 8: val_loss improved from 0.88859 to 0.86926, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7273 - loss: 0.6341 - val_accuracy: 0.5664 - val_loss: 0.8693 - learning_rate: 6.0000e-05\nEpoch 9/50\n\nEpoch 9: val_loss improved from 0.86926 to 0.85983, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7362 - loss: 0.6208 - val_accuracy: 0.5761 - val_loss: 0.8598 - learning_rate: 6.0000e-05\nEpoch 10/50\n\nEpoch 10: val_loss improved from 0.85983 to 0.85236, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7429 - loss: 0.6093 - val_accuracy: 0.5816 - val_loss: 0.8524 - learning_rate: 6.0000e-05\nEpoch 11/50\n\nEpoch 11: val_loss improved from 0.85236 to 0.84217, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7498 - loss: 0.5988 - val_accuracy: 0.5902 - val_loss: 0.8422 - learning_rate: 6.0000e-05\nEpoch 12/50\n\nEpoch 12: val_loss improved from 0.84217 to 0.83261, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7543 - loss: 0.5904 - val_accuracy: 0.5989 - val_loss: 0.8326 - learning_rate: 6.0000e-05\nEpoch 13/50\n\nEpoch 13: val_loss improved from 0.83261 to 0.82786, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7592 - loss: 0.5819 - val_accuracy: 0.6060 - val_loss: 0.8279 - learning_rate: 6.0000e-05\nEpoch 14/50\n\nEpoch 14: val_loss improved from 0.82786 to 0.81930, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7633 - loss: 0.5739 - val_accuracy: 0.6137 - val_loss: 0.8193 - learning_rate: 6.0000e-05\nEpoch 15/50\n\nEpoch 15: val_loss improved from 0.81930 to 0.81278, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7679 - loss: 0.5668 - val_accuracy: 0.6211 - val_loss: 0.8128 - learning_rate: 6.0000e-05\nEpoch 16/50\n\nEpoch 16: val_loss improved from 0.81278 to 0.80358, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7713 - loss: 0.5598 - val_accuracy: 0.6263 - val_loss: 0.8036 - learning_rate: 6.0000e-05\nEpoch 17/50\n\nEpoch 17: val_loss improved from 0.80358 to 0.80164, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7746 - loss: 0.5533 - val_accuracy: 0.6301 - val_loss: 0.8016 - learning_rate: 6.0000e-05\nEpoch 18/50\n\nEpoch 18: val_loss improved from 0.80164 to 0.79595, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7783 - loss: 0.5464 - val_accuracy: 0.6353 - val_loss: 0.7960 - learning_rate: 6.0000e-05\nEpoch 19/50\n\nEpoch 19: val_loss improved from 0.79595 to 0.78764, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7811 - loss: 0.5413 - val_accuracy: 0.6421 - val_loss: 0.7876 - learning_rate: 6.0000e-05\nEpoch 20/50\n\nEpoch 20: val_loss improved from 0.78764 to 0.78661, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7842 - loss: 0.5350 - val_accuracy: 0.6442 - val_loss: 0.7866 - learning_rate: 6.0000e-05\nEpoch 21/50\n\nEpoch 21: val_loss improved from 0.78661 to 0.77816, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7878 - loss: 0.5296 - val_accuracy: 0.6487 - val_loss: 0.7782 - learning_rate: 6.0000e-05\nEpoch 22/50\n\nEpoch 22: val_loss improved from 0.77816 to 0.77190, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7908 - loss: 0.5234 - val_accuracy: 0.6561 - val_loss: 0.7719 - learning_rate: 6.0000e-05\nEpoch 23/50\n\nEpoch 23: val_loss improved from 0.77190 to 0.76597, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7930 - loss: 0.5183 - val_accuracy: 0.6619 - val_loss: 0.7660 - learning_rate: 6.0000e-05\nEpoch 24/50\n\nEpoch 24: val_loss improved from 0.76597 to 0.76243, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7955 - loss: 0.5126 - val_accuracy: 0.6639 - val_loss: 0.7624 - learning_rate: 6.0000e-05\nEpoch 25/50\n\nEpoch 25: val_loss improved from 0.76243 to 0.75515, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.7983 - loss: 0.5075 - val_accuracy: 0.6693 - val_loss: 0.7552 - learning_rate: 6.0000e-05\nEpoch 26/50\n\nEpoch 26: val_loss improved from 0.75515 to 0.75016, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8012 - loss: 0.5026 - val_accuracy: 0.6738 - val_loss: 0.7502 - learning_rate: 6.0000e-05\nEpoch 27/50\n\nEpoch 27: val_loss did not improve from 0.75016\n1592/1592 - 35s - 22ms/step - accuracy: 0.8034 - loss: 0.4979 - val_accuracy: 0.6743 - val_loss: 0.7518 - learning_rate: 6.0000e-05\nEpoch 28/50\n\nEpoch 28: val_loss improved from 0.75016 to 0.74375, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8059 - loss: 0.4928 - val_accuracy: 0.6784 - val_loss: 0.7437 - learning_rate: 6.0000e-05\nEpoch 29/50\n\nEpoch 29: val_loss improved from 0.74375 to 0.74229, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8077 - loss: 0.4891 - val_accuracy: 0.6792 - val_loss: 0.7423 - learning_rate: 6.0000e-05\nEpoch 30/50\n\nEpoch 30: val_loss did not improve from 0.74229\n1592/1592 - 34s - 22ms/step - accuracy: 0.8103 - loss: 0.4843 - val_accuracy: 0.6801 - val_loss: 0.7426 - learning_rate: 6.0000e-05\nEpoch 31/50\n\nEpoch 31: val_loss improved from 0.74229 to 0.73483, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8114 - loss: 0.4811 - val_accuracy: 0.6832 - val_loss: 0.7348 - learning_rate: 6.0000e-05\nEpoch 32/50\n\nEpoch 32: val_loss did not improve from 0.73483\n1592/1592 - 34s - 22ms/step - accuracy: 0.8135 - loss: 0.4769 - val_accuracy: 0.6828 - val_loss: 0.7405 - learning_rate: 6.0000e-05\nEpoch 33/50\n\nEpoch 33: val_loss did not improve from 0.73483\n1592/1592 - 35s - 22ms/step - accuracy: 0.8147 - loss: 0.4736 - val_accuracy: 0.6833 - val_loss: 0.7356 - learning_rate: 6.0000e-05\nEpoch 34/50\n\nEpoch 34: val_loss improved from 0.73483 to 0.72826, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8209 - loss: 0.4622 - val_accuracy: 0.6875 - val_loss: 0.7283 - learning_rate: 1.2000e-05\nEpoch 35/50\n\nEpoch 35: val_loss improved from 0.72826 to 0.72694, saving model to my_model_weights.weights.h5\n1592/1592 - 35s - 22ms/step - accuracy: 0.8211 - loss: 0.4599 - val_accuracy: 0.6880 - val_loss: 0.7269 - learning_rate: 1.2000e-05\nEpoch 36/50\n\nEpoch 36: val_loss did not improve from 0.72694\n1592/1592 - 35s - 22ms/step - accuracy: 0.8222 - loss: 0.4592 - val_accuracy: 0.6882 - val_loss: 0.7281 - learning_rate: 1.2000e-05\nEpoch 37/50\n\nEpoch 37: val_loss did not improve from 0.72694\n1592/1592 - 34s - 22ms/step - accuracy: 0.8220 - loss: 0.4580 - val_accuracy: 0.6879 - val_loss: 0.7279 - learning_rate: 1.2000e-05\nEpoch 38/50\n\nEpoch 38: val_loss did not improve from 0.72694\n1592/1592 - 35s - 22ms/step - accuracy: 0.8237 - loss: 0.4555 - val_accuracy: 0.6899 - val_loss: 0.7275 - learning_rate: 2.4000e-06\nEpoch 39/50\n\nEpoch 39: val_loss did not improve from 0.72694\n1592/1592 - 34s - 21ms/step - accuracy: 0.8238 - loss: 0.4556 - val_accuracy: 0.6896 - val_loss: 0.7275 - learning_rate: 2.4000e-06\nEpoch 40/50\n\nEpoch 40: val_loss did not improve from 0.72694\n1592/1592 - 35s - 22ms/step - accuracy: 0.8241 - loss: 0.4553 - val_accuracy: 0.6899 - val_loss: 0.7280 - learning_rate: 1.0000e-06\nEpoch 40: early stopping\nRestoring model weights from the end of the best epoch: 35.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"Model Testing","metadata":{}},{"cell_type":"code","source":"deeplob.load_weights(checkpoint_filepath)\npred = deeplob.predict(testX_CNN, batch_size=128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T05:59:59.398536Z","iopub.execute_input":"2025-07-14T05:59:59.399318Z","iopub.status.idle":"2025-07-14T06:00:16.831879Z","shell.execute_reply.started":"2025-07-14T05:59:59.399274Z","shell.execute_reply":"2025-07-14T06:00:16.831239Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1090/1090\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print('accuracy_score:', accuracy_score(np.argmax(testY_CNN, axis=1), np.argmax(pred, axis=1)))\nprint(classification_report(np.argmax(testY_CNN, axis=1), np.argmax(pred, axis=1), digits=4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-14T06:22:14.880479Z","iopub.execute_input":"2025-07-14T06:22:14.881066Z","iopub.status.idle":"2025-07-14T06:22:14.946983Z","shell.execute_reply.started":"2025-07-14T06:22:14.881042Z","shell.execute_reply":"2025-07-14T06:22:14.946329Z"}},"outputs":[{"name":"stdout","text":"accuracy_score: 0.7711917871071347\n              precision    recall  f1-score   support\n\n           0     0.7368    0.7750    0.7554     47915\n           1     0.8377    0.7937    0.8151     48050\n           2     0.7414    0.7422    0.7418     43523\n\n    accuracy                         0.7712    139488\n   macro avg     0.7720    0.7703    0.7708    139488\nweighted avg     0.7730    0.7712    0.7717    139488\n\n","output_type":"stream"}],"execution_count":13}]}