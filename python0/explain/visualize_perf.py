"""Visualize C++ performance benchmark results.

This script reads CSV files generated by perf_benchmark.cpp and creates
comprehensive visualizations:
1. Latency distribution histograms
2. Percentile comparison charts
3. Throughput scaling analysis
"""
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict

sns.set_style("whitegrid")


def load_latency_csv(filepath: str) -> np.ndarray:
    """Load latency data from CSV (in microseconds)."""
    df = pd.read_csv(filepath)
    return df['latency_us'].values


def plot_latency_histogram(data: Dict[str, np.ndarray], 
                           output_path: str = "artifacts/plots/latency_histogram.png"):
    """Plot latency distribution histograms."""
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    axes = axes.flatten()
    
    colors = ['steelblue', 'coral', 'forestgreen', 'purple']
    
    for idx, (name, latencies) in enumerate(data.items()):
        if idx >= 4:
            break
        
        ax = axes[idx]
        
        # Histogram
        ax.hist(latencies, bins=50, color=colors[idx], alpha=0.7, edgecolor='black')
        
        # Stats annotations
        p50 = np.percentile(latencies, 50)
        p95 = np.percentile(latencies, 95)
        p99 = np.percentile(latencies, 99)
        
        ax.axvline(p50, color='red', linestyle='--', linewidth=2, label=f'P50: {p50:.2f}¬µs')
        ax.axvline(p95, color='orange', linestyle='--', linewidth=2, label=f'P95: {p95:.2f}¬µs')
        ax.axvline(p99, color='darkred', linestyle='--', linewidth=2, label=f'P99: {p99:.2f}¬µs')
        
        ax.set_xlabel('Latency (¬µs)', fontsize=11, fontweight='bold')
        ax.set_ylabel('Frequency', fontsize=11, fontweight='bold')
        ax.set_title(name.replace('_', ' ').title(), fontsize=12, fontweight='bold')
        ax.legend(fontsize=9)
        ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ Saved latency histogram to {output_path}")
    
    return fig


def plot_percentile_comparison(data: Dict[str, np.ndarray],
                               output_path: str = "artifacts/plots/latency_percentiles.png"):
    """Plot percentile comparison across different operations."""
    percentiles = [50, 95, 99, 99.9]
    
    results = []
    for name, latencies in data.items():
        for p in percentiles:
            val = np.percentile(latencies, p)
            results.append({
                'Operation': name.replace('_', ' ').title(),
                'Percentile': f'P{p:.1f}',
                'Latency_us': val
            })
    
    df = pd.DataFrame(results)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    # Grouped bar chart
    operations = df['Operation'].unique()
    percentile_labels = df['Percentile'].unique()
    
    x = np.arange(len(operations))
    width = 0.2
    
    colors = ['steelblue', 'coral', 'forestgreen', 'purple']
    
    for i, p_label in enumerate(percentile_labels):
        subset = df[df['Percentile'] == p_label]
        values = [subset[subset['Operation'] == op]['Latency_us'].values[0] 
                  for op in operations]
        
        ax.bar(x + i * width, values, width, label=p_label, 
               color=colors[i], alpha=0.8, edgecolor='black')
    
    ax.set_xlabel('Operation', fontsize=12, fontweight='bold')
    ax.set_ylabel('Latency (¬µs)', fontsize=12, fontweight='bold')
    ax.set_title('Latency Percentile Comparison', fontsize=14, fontweight='bold')
    ax.set_xticks(x + width * 1.5)
    ax.set_xticklabels(operations, rotation=15, ha='right')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3, axis='y')
    
    plt.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ Saved percentile comparison to {output_path}")
    
    return fig


def plot_latency_cdf(data: Dict[str, np.ndarray],
                     output_path: str = "artifacts/plots/latency_cdf.png"):
    """Plot cumulative distribution function of latencies."""
    fig, ax = plt.subplots(figsize=(10, 6))
    
    colors = ['steelblue', 'coral', 'forestgreen', 'purple', 'orange']
    
    for idx, (name, latencies) in enumerate(data.items()):
        sorted_lat = np.sort(latencies)
        cdf = np.arange(1, len(sorted_lat) + 1) / len(sorted_lat) * 100
        
        ax.plot(sorted_lat, cdf, linewidth=2, label=name.replace('_', ' ').title(),
                color=colors[idx % len(colors)])
    
    # Reference lines
    for p in [50, 95, 99]:
        ax.axhline(p, color='gray', linestyle='--', alpha=0.3)
        ax.text(ax.get_xlim()[1] * 0.95, p + 1, f'P{p}', 
                fontsize=9, color='gray', ha='right')
    
    ax.set_xlabel('Latency (¬µs)', fontsize=11, fontweight='bold')
    ax.set_ylabel('Cumulative Probability (%)', fontsize=11, fontweight='bold')
    ax.set_title('Latency CDF', fontsize=12, fontweight='bold')
    ax.legend(fontsize=9, loc='lower right')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(left=0)
    ax.set_ylim([0, 100])
    
    plt.tight_layout()
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ Saved latency CDF to {output_path}")
    
    return fig


def generate_summary_table(data: Dict[str, np.ndarray],
                           output_path: str = "artifacts/perf/summary_table.csv"):
    """Generate summary statistics table."""
    summary = []
    
    for name, latencies in data.items():
        stats = {
            'Operation': name,
            'Count': len(latencies),
            'Mean_us': np.mean(latencies),
            'Std_us': np.std(latencies),
            'Min_us': np.min(latencies),
            'P50_us': np.percentile(latencies, 50),
            'P95_us': np.percentile(latencies, 95),
            'P99_us': np.percentile(latencies, 99),
            'P99.9_us': np.percentile(latencies, 99.9),
            'Max_us': np.max(latencies),
        }
        summary.append(stats)
    
    df = pd.DataFrame(summary)
    
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    df.to_csv(output_path, index=False, float_format='%.2f')
    print(f"‚úÖ Saved summary table to {output_path}")
    
    # Print to console
    print("\n" + "="*80)
    print("PERFORMANCE SUMMARY")
    print("="*80)
    print(df.to_string(index=False))
    print("="*80 + "\n")
    
    return df


def main():
    """Main visualization pipeline."""
    print("üìä Performance Visualization Pipeline\n")
    
    # Load data
    data_files = {
        'feature_extraction': 'artifacts/perf/feature_extraction_latency.csv',
        'onnx_inference': 'artifacts/perf/onnx_inference_latency.csv',
        'e2e_pipeline': 'artifacts/perf/e2e_pipeline_latency.csv',
    }
    
    data = {}
    for name, filepath in data_files.items():
        if os.path.exists(filepath):
            data[name] = load_latency_csv(filepath)
            print(f"‚úÖ Loaded {name}: {len(data[name])} samples")
        else:
            print(f"‚ö†Ô∏è  File not found: {filepath}")
    
    if not data:
        print("\n‚ùå No data files found! Run perf_benchmark first.")
        print("   cd cpp/build && ./perf_benchmark")
        return
    
    print()
    
    # Generate visualizations
    plot_latency_histogram(data)
    plot_percentile_comparison(data)
    plot_latency_cdf(data)
    
    # Generate summary table
    generate_summary_table(data)
    
    print("\n‚úÖ All visualizations generated!")
    print("üìÅ Results saved to artifacts/plots/ and artifacts/perf/")


if __name__ == "__main__":
    main()
